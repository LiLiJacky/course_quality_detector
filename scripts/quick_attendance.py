"""
Fast attendance identification by sampling video frames and matching detected faces to a gallery.

Inputs:
- video: path to video file
- gallery_dir: directory containing embeddings.npy + meta.json generated by face_gallery.py

Outputs:
- attendance JSON with unique ids and counts
"""

import argparse
import json
import platform
from pathlib import Path
from typing import Dict, List, Tuple

import cv2
import numpy as np


def load_gallery(gallery_dir: Path) -> Tuple[np.ndarray, List[dict]]:
    emb_path = gallery_dir / "embeddings.npy"
    meta_path = gallery_dir / "meta.json"
    if not emb_path.exists() or not meta_path.exists():
        raise SystemExit(f"Gallery files missing in {gallery_dir}")
    embeddings = np.load(emb_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        meta = json.load(f)
    if embeddings.shape[0] != len(meta):
        raise SystemExit("Embedding count does not match meta length.")
    norm = np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-8
    embeddings = embeddings / norm
    return embeddings.astype(np.float32), meta


def _select_providers() -> list:
    """Prefer CUDA on Windows/Linux if available; fallback to CPU."""
    try:
        import torch

        if torch.cuda.is_available() and platform.system().lower() in ("windows", "linux"):
            return ["CUDAExecutionProvider", "CPUExecutionProvider"]
    except Exception:
        pass
    return ["CPUExecutionProvider"]


def _init_face_app(det_name: str):
    try:
        from insightface.app import FaceAnalysis
    except ImportError as exc:
        raise SystemExit(
            "insightface is required. Install with `pip install insightface`."
        ) from exc
    providers = _select_providers()
    app = FaceAnalysis(
        name=det_name,
        providers=providers,
        allowed_modules=["detection", "recognition"],
    )
    app.prepare(ctx_id=0, det_size=(960, 960))
    return app


def quick_attendance(
    video_path: Path,
    gallery_dir: Path,
    det_name: str,
    threshold: float,
    frame_stride: int,
    max_frames: int | None,
    min_count: int,
    allowed_ids: set[str] | None,
    output_path: Path,
) -> None:
    embeddings, meta = load_gallery(gallery_dir)
    gallery_ids = [item["student_id"] for item in meta]
    app = _init_face_app(det_name)

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise SystemExit(f"Failed to open video {video_path}")

    recognized: Dict[str, int] = {}
    total_faces = 0
    matches: List[dict] = []

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    limit = max_frames if max_frames is not None else total_frames

    frame_idx = 0
    processed = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % frame_stride != 0:
            frame_idx += 1
            continue
        if processed >= limit:
            break
        processed += 1

        faces = app.get(frame)
        if not faces:
            frame_idx += 1
            continue
        faces.sort(key=lambda f: f.det_score, reverse=True)
        total_faces += len(faces)
        for face in faces:
            emb = face.embedding.astype(np.float32)
            emb_norm = emb / (np.linalg.norm(emb) + 1e-8)
            sims = np.dot(embeddings, emb_norm)
            best_idx = int(np.argmax(sims))
            best_sim = float(sims[best_idx])
            best_id = gallery_ids[best_idx] if best_sim >= threshold else None
            if best_id:
                recognized[best_id] = recognized.get(best_id, 0) + 1
            matches.append(
                {
                    "frame": frame_idx,
                    "best_id": best_id,
                    "similarity": best_sim,
                    "bbox": list(map(float, face.bbox)),
                    "det_score": float(face.det_score),
                }
            )
        frame_idx += 1

    cap.release()

    if allowed_ids:
        recognized = {k: v for k, v in recognized.items() if k in allowed_ids}
    recognized = {k: v for k, v in recognized.items() if v >= min_count}
    attendance_ids = sorted(recognized.keys())
    output = {
        "attendance_ids": attendance_ids,
        "recognized_counts": recognized,
        "matches": matches,
        "threshold": threshold,
        "frame_stride": frame_stride,
        "frames_processed": processed,
        "video": str(video_path),
        "faces_detected": total_faces,
        "min_count": min_count,
    }
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(
        f"Saved attendance for {len(attendance_ids)} students "
        f"from {processed} sampled frames to {output_path}"
    )
    return output


def parse_args():
    parser = argparse.ArgumentParser(description="Quick attendance from video frames")
    parser.add_argument("--video", type=Path, required=True, help="Video path")
    parser.add_argument(
        "--gallery_dir",
        type=Path,
        default=Path("outputs/face_gallery"),
        help="Directory containing embeddings.npy and meta.json",
    )
    parser.add_argument(
        "--det_name",
        type=str,
        default="buffalo_l",
        help="InsightFace detection/recognition pack name",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.3,
        help="Cosine similarity threshold to accept a match",
    )
    parser.add_argument(
        "--frame_stride",
        type=int,
        default=10,
        help="Sample every N frames",
    )
    parser.add_argument(
        "--max_frames",
        type=int,
        default=None,
        help="Optional limit on number of sampled frames",
    )
    parser.add_argument(
        "--min_count",
        type=int,
        default=5,
        help="Minimum matched occurrences to accept an ID",
    )
    parser.add_argument(
        "--allowed_ids",
        type=Path,
        default=None,
        help="Optional text file with allowed IDs (one per line); others ignored",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("outputs/attendance.json"),
        help="Path to save attendance JSON",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    roster = None
    if args.allowed_ids:
        roster = {line.strip() for line in args.allowed_ids.read_text().splitlines() if line.strip()}
    quick_attendance(
        args.video,
        args.gallery_dir,
        args.det_name,
        args.threshold,
        args.frame_stride,
        args.max_frames,
        args.min_count,
        roster,
        args.output,
    )
